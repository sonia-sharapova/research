{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a2a95ce1-a2c3-4f47-903d-5442f51c112d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scanpy as sc\n",
    "import argparse\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import scipy.sparse as sp\n",
    "import os\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.distributions import NegativeBinomial\n",
    "from pyro.distributions.zero_inflated import ZeroInflatedNegativeBinomial\n",
    "\n",
    "#calculate ARI score\n",
    "from sklearn.metrics import adjusted_rand_score, normalized_mutual_info_score, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d07dbbda-5ae0-4954-9cf1-bed140f11cbe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7fe6384e1b70>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c31e2bae-8ccc-4d0a-bf00-ea8a65a53a08",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8675d207-113b-4b3c-bcc0-6b4656f0e894",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['TCGA-A2-A0D0-01' 0.7618 0.7481 ... 0.0132 1.6853 1]\n",
      " ['TCGA-BH-A0HK-01' 1.4195 0.9259 ... 0.0 0.9144 3]\n",
      " ['TCGA-C8-A12T-01' 0.318 0.0 ... 0.0 0.0087 2]\n",
      " ...\n",
      " ['TCGA-E2-A159-01' 0.7527 0.5561 ... 0.0 0.0 1]\n",
      " ['TCGA-A2-A0T3-01' 0.0126 0.0 ... 0.0628 0.4018 4]\n",
      " ['TCGA-A2-A0YD-01' 0.9947 0.407 ... 0.0 0.267 3]]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Composite.Element.REF</th>\n",
       "      <th>A1BG</th>\n",
       "      <th>A2M</th>\n",
       "      <th>A2ML1</th>\n",
       "      <th>AAAS</th>\n",
       "      <th>AACS</th>\n",
       "      <th>AAED1</th>\n",
       "      <th>AAGAB</th>\n",
       "      <th>AAK1</th>\n",
       "      <th>AAMDC</th>\n",
       "      <th>...</th>\n",
       "      <th>ZSWIM8</th>\n",
       "      <th>ZW10</th>\n",
       "      <th>ZWILCH</th>\n",
       "      <th>ZWINT</th>\n",
       "      <th>ZXDC</th>\n",
       "      <th>ZYG11B</th>\n",
       "      <th>ZYX</th>\n",
       "      <th>ZZEF1</th>\n",
       "      <th>ZZZ3</th>\n",
       "      <th>cancer_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TCGA-A2-A0D0-01</td>\n",
       "      <td>0.7618</td>\n",
       "      <td>0.7481</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1.3759</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0160</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.4656</td>\n",
       "      <td>0.2251</td>\n",
       "      <td>0.7310</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1.1508</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0132</td>\n",
       "      <td>1.6853</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TCGA-BH-A0HK-01</td>\n",
       "      <td>1.4195</td>\n",
       "      <td>0.9259</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.6716</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0808</td>\n",
       "      <td>0.1219</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.2386</td>\n",
       "      <td>0.0193</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.6027</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.9144</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TCGA-C8-A12T-01</td>\n",
       "      <td>0.3180</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.1638</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.4738</td>\n",
       "      <td>0.0433</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.2109</td>\n",
       "      <td>0.2311</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.2617</td>\n",
       "      <td>0.3484</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0087</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TCGA-A2-A0D2-01</td>\n",
       "      <td>0.0128</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.3808</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3719</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0169</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0927</td>\n",
       "      <td>0.2363</td>\n",
       "      <td>0.7675</td>\n",
       "      <td>0.6338</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.1919</td>\n",
       "      <td>0.3602</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.3334</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TCGA-C8-A12U-01</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.1080</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.1073</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.1598</td>\n",
       "      <td>0.5379</td>\n",
       "      <td>0.0397</td>\n",
       "      <td>0.0925</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.1183</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>TCGA-BH-A18Q-01</td>\n",
       "      <td>0.0771</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.7431</td>\n",
       "      <td>0.2510</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.1511</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.1084</td>\n",
       "      <td>0.0598</td>\n",
       "      <td>0.0921</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.1626</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0586</td>\n",
       "      <td>0.2732</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>TCGA-C8-A130-01</td>\n",
       "      <td>0.0997</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0296</td>\n",
       "      <td>0.1863</td>\n",
       "      <td>0.1723</td>\n",
       "      <td>0.0922</td>\n",
       "      <td>...</td>\n",
       "      <td>0.1842</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.1901</td>\n",
       "      <td>0.1515</td>\n",
       "      <td>0.2357</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0072</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>TCGA-E2-A159-01</td>\n",
       "      <td>0.7527</td>\n",
       "      <td>0.5561</td>\n",
       "      <td>3.3277</td>\n",
       "      <td>0.8935</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0975</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.4146</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.9516</td>\n",
       "      <td>0.6781</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1.3542</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>TCGA-A2-A0T3-01</td>\n",
       "      <td>0.0126</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0796</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.2538</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.3311</td>\n",
       "      <td>0.0874</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0628</td>\n",
       "      <td>0.4018</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>TCGA-A2-A0YD-01</td>\n",
       "      <td>0.9947</td>\n",
       "      <td>0.4070</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.1486</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.2440</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.3986</td>\n",
       "      <td>0.0251</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.2670</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>105 rows × 9735 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Composite.Element.REF    A1BG     A2M   A2ML1    AAAS  AACS   AAED1  \\\n",
       "0         TCGA-A2-A0D0-01  0.7618  0.7481  0.0000  1.3759   0.0  0.0000   \n",
       "1         TCGA-BH-A0HK-01  1.4195  0.9259  0.0000  0.6716   0.0  0.0000   \n",
       "2         TCGA-C8-A12T-01  0.3180  0.0000  0.0000  0.1638   0.0  0.0000   \n",
       "3         TCGA-A2-A0D2-01  0.0128  0.0000  0.0000  0.3808   0.0  0.3719   \n",
       "4         TCGA-C8-A12U-01  0.0000  0.1080  0.0000  0.0000   0.0  0.0000   \n",
       "..                    ...     ...     ...     ...     ...   ...     ...   \n",
       "100       TCGA-BH-A18Q-01  0.0771  0.0000  0.7431  0.2510   0.0  0.0000   \n",
       "101       TCGA-C8-A130-01  0.0997  0.0000  0.0000  0.0000   0.0  0.0296   \n",
       "102       TCGA-E2-A159-01  0.7527  0.5561  3.3277  0.8935   0.0  0.0000   \n",
       "103       TCGA-A2-A0T3-01  0.0126  0.0000  0.0000  0.0796   0.0  0.0000   \n",
       "104       TCGA-A2-A0YD-01  0.9947  0.4070  0.0000  0.1486   0.0  0.0000   \n",
       "\n",
       "      AAGAB    AAK1   AAMDC  ...  ZSWIM8    ZW10  ZWILCH   ZWINT    ZXDC  \\\n",
       "0    0.0000  0.0160  0.0000  ...  0.4656  0.2251  0.7310  0.0000  0.0000   \n",
       "1    0.0808  0.1219  0.0000  ...  0.2386  0.0193  0.0000  0.0000  0.0000   \n",
       "2    0.4738  0.0433  0.0000  ...  0.0000  0.0000  0.2109  0.2311  0.0000   \n",
       "3    0.0000  0.0169  0.0000  ...  0.0927  0.2363  0.7675  0.6338  0.0000   \n",
       "4    0.1073  0.0000  0.0000  ...  0.0000  0.0000  0.0000  0.1598  0.5379   \n",
       "..      ...     ...     ...  ...     ...     ...     ...     ...     ...   \n",
       "100  0.0000  0.1511  0.0000  ...  0.1084  0.0598  0.0921  0.0000  0.1626   \n",
       "101  0.1863  0.1723  0.0922  ...  0.1842  0.0000  0.0000  0.1901  0.1515   \n",
       "102  0.0000  0.0975  0.0000  ...  0.4146  0.0000  0.9516  0.6781  0.0000   \n",
       "103  0.0000  0.2538  0.0000  ...  0.0000  0.0000  0.3311  0.0874  0.0000   \n",
       "104  0.0000  0.2440  0.0000  ...  0.0000  0.0000  0.0000  0.0000  0.0000   \n",
       "\n",
       "     ZYG11B     ZYX   ZZEF1    ZZZ3  cancer_type  \n",
       "0    1.1508  0.0000  0.0132  1.6853            1  \n",
       "1    0.6027  0.0000  0.0000  0.9144            3  \n",
       "2    0.2617  0.3484  0.0000  0.0087            2  \n",
       "3    0.1919  0.3602  0.0000  0.3334            1  \n",
       "4    0.0397  0.0925  0.0000  0.1183            4  \n",
       "..      ...     ...     ...     ...          ...  \n",
       "100  0.0000  0.0000  0.0586  0.2732            1  \n",
       "101  0.2357  0.0000  0.0000  0.0072            4  \n",
       "102  1.3542  0.0000  0.0000  0.0000            1  \n",
       "103  0.0000  0.0000  0.0628  0.4018            4  \n",
       "104  0.3986  0.0251  0.0000  0.2670            3  \n",
       "\n",
       "[105 rows x 9735 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import math\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "tmp = []\n",
    "tmplist = []\n",
    "pd_celldata = pd.read_csv(\"proteinOutFileCat_nn.csv\", sep=',', header=0)\n",
    "pd_celldata = pd_celldata.rename({'Cancer Type': 'cancer_type'}, axis=1)\n",
    "\n",
    "celldata = pd_celldata.to_numpy()\n",
    "\n",
    "features = list(pd_celldata)\n",
    "\n",
    "#get column names\n",
    "i_d = []\n",
    "for row in celldata:\n",
    "    i_d.append(row[0])\n",
    "    \n",
    "# Remove first column: patients\n",
    "i_d = i_d[1:]\n",
    "\n",
    "celldata_t = celldata[:,:]\n",
    "print(celldata_t) \n",
    "\n",
    "pd_celldata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4f295bbf-b285-4513-aae3-51345740dd8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "numlist=[]; obj_ind=[]\n",
    "labels = []\n",
    "for ind in range(celldata_t.shape[0]):\n",
    "    x = celldata_t[ind,:].astype(np.str)\n",
    "    numlist.append(x.astype(np.str))\n",
    "\n",
    "i = 0\n",
    "newList = []\n",
    "for row in numlist:\n",
    "    newList.append(row)\n",
    "    labels.append(row[-1])\n",
    "    i = i+1\n",
    "    \n",
    "    \n",
    "\n",
    "numlist = newList\n",
    "numlist = np.array(numlist)\n",
    "\n",
    "pd_celldata_t = pd_celldata.drop(columns=\"Composite.Element.REF\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "abf1fa24-434f-419b-910c-83e33fc24964",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       A1BG     A2M   A2ML1    AAAS  AACS   AAED1   AAGAB    AAK1   AAMDC  \\\n",
      "0    0.7618  0.7481  0.0000  1.3759   0.0  0.0000  0.0000  0.0160  0.0000   \n",
      "1    1.4195  0.9259  0.0000  0.6716   0.0  0.0000  0.0808  0.1219  0.0000   \n",
      "2    0.3180  0.0000  0.0000  0.1638   0.0  0.0000  0.4738  0.0433  0.0000   \n",
      "3    0.0128  0.0000  0.0000  0.3808   0.0  0.3719  0.0000  0.0169  0.0000   \n",
      "4    0.0000  0.1080  0.0000  0.0000   0.0  0.0000  0.1073  0.0000  0.0000   \n",
      "..      ...     ...     ...     ...   ...     ...     ...     ...     ...   \n",
      "100  0.0771  0.0000  0.7431  0.2510   0.0  0.0000  0.0000  0.1511  0.0000   \n",
      "101  0.0997  0.0000  0.0000  0.0000   0.0  0.0296  0.1863  0.1723  0.0922   \n",
      "102  0.7527  0.5561  3.3277  0.8935   0.0  0.0000  0.0000  0.0975  0.0000   \n",
      "103  0.0126  0.0000  0.0000  0.0796   0.0  0.0000  0.0000  0.2538  0.0000   \n",
      "104  0.9947  0.4070  0.0000  0.1486   0.0  0.0000  0.0000  0.2440  0.0000   \n",
      "\n",
      "       AAMP  ...  ZSWIM8    ZW10  ZWILCH   ZWINT    ZXDC  ZYG11B     ZYX  \\\n",
      "0    0.0000  ...  0.4656  0.2251  0.7310  0.0000  0.0000  1.1508  0.0000   \n",
      "1    0.2943  ...  0.2386  0.0193  0.0000  0.0000  0.0000  0.6027  0.0000   \n",
      "2    0.3008  ...  0.0000  0.0000  0.2109  0.2311  0.0000  0.2617  0.3484   \n",
      "3    0.0000  ...  0.0927  0.2363  0.7675  0.6338  0.0000  0.1919  0.3602   \n",
      "4    0.4147  ...  0.0000  0.0000  0.0000  0.1598  0.5379  0.0397  0.0925   \n",
      "..      ...  ...     ...     ...     ...     ...     ...     ...     ...   \n",
      "100  0.0000  ...  0.1084  0.0598  0.0921  0.0000  0.1626  0.0000  0.0000   \n",
      "101  0.0727  ...  0.1842  0.0000  0.0000  0.1901  0.1515  0.2357  0.0000   \n",
      "102  0.0000  ...  0.4146  0.0000  0.9516  0.6781  0.0000  1.3542  0.0000   \n",
      "103  0.0994  ...  0.0000  0.0000  0.3311  0.0874  0.0000  0.0000  0.0000   \n",
      "104  0.0000  ...  0.0000  0.0000  0.0000  0.0000  0.0000  0.3986  0.0251   \n",
      "\n",
      "      ZZEF1    ZZZ3  cancer_type  \n",
      "0    0.0132  1.6853            1  \n",
      "1    0.0000  0.9144            3  \n",
      "2    0.0000  0.0087            2  \n",
      "3    0.0000  0.3334            1  \n",
      "4    0.0000  0.1183            4  \n",
      "..      ...     ...          ...  \n",
      "100  0.0586  0.2732            1  \n",
      "101  0.0000  0.0072            4  \n",
      "102  0.0000  0.0000            1  \n",
      "103  0.0628  0.4018            4  \n",
      "104  0.0000  0.2670            3  \n",
      "\n",
      "[105 rows x 9734 columns]\n"
     ]
    }
   ],
   "source": [
    "print(pd_celldata_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "13450e3a-3f56-4840-9966-9fefc149c6fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X, y = pd_celldata_t.drop(labels='cancer_type', axis=1),pd_celldata_t['cancer_type']\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3,\n",
    "    stratify=y, random_state=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "76d2aeaa-e9fb-45e7-a10b-0d5721ec0299",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "73\n",
      "40    1\n",
      "89    3\n",
      "59    1\n",
      "74    3\n",
      "61    3\n",
      "     ..\n",
      "91    3\n",
      "79    0\n",
      "62    4\n",
      "97    4\n",
      "49    3\n",
      "Name: cancer_type, Length: 73, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(len(X_train))\n",
    "print(y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d43b6902-fa66-45bc-b5c0-5fb7ebac6bc3",
   "metadata": {},
   "source": [
    "## Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "645b62e9-9747-422c-a8eb-8253fcacc470",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_norm1 = X_train.div(X_train.sum(axis=1), axis=0)\n",
    "X_train_norm2 = X_train.div(X_train.sum(axis=0), axis=1)\n",
    "X_train_norm2=X_train_norm2.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "93105fd0-deda-465d-9b2e-e59e91fa8799",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scanpy==1.8.2 anndata==0.7.6 umap==0.5.1 numpy==1.19.5 scipy==1.7.1 pandas==1.3.3 scikit-learn==0.24.1 statsmodels==0.13.0rc0 python-igraph==0.9.8 pynndescent==0.5.4\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import scanpy as sc\n",
    "sc.settings.verbosity = 3  # verbosity: errors (0), warnings (1), info (2), hints (3)\n",
    "sc.logging.print_header()\n",
    "sc.settings.set_figure_params(dpi=80, facecolor=\"white\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b3687dd5-db6f-4675-b1f2-bfd2c11f0067",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for adata\n",
    "\n",
    "import anndata as ad\n",
    "\n",
    "X_train_a = np.array(X_train_norm1)\n",
    "adata = ad.AnnData(X_train_a)\n",
    "\n",
    "\n",
    "adata.uns[\"name\"] = \"prot\"\n",
    "\n",
    "y_train_str = []\n",
    "for i in y_train:\n",
    "    y_train_str.append(str(i)) # convert to strings so that they can be recognized by scanpy\n",
    "adata.obs['true_labels'] = y_train_str\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91e1b502-bfb5-4099-8811-c6c18ba026a3",
   "metadata": {},
   "source": [
    "## preprocessing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a9c2dc4c-1f5e-48be-a40a-7625072db314",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AnnData object with n_obs × n_vars = 73 × 9733\n",
       "    obs: 'true_labels'\n",
       "    uns: 'name'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a3848c47-3879-4862-a19b-5d27d9677f3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.00000000e+00, 2.68686737e-04, 6.57511118e-04, ...,\n",
       "        3.68890527e-04, 2.37525783e-05, 1.14715025e-04],\n",
       "       [7.44993158e-04, 4.39132418e-04, 0.00000000e+00, ...,\n",
       "        3.31292540e-05, 1.18933269e-04, 0.00000000e+00],\n",
       "       [6.35966484e-04, 5.79013315e-04, 3.37664213e-04, ...,\n",
       "        1.80653151e-04, 4.62237549e-05, 2.60375091e-04],\n",
       "       ...,\n",
       "       [3.06582078e-04, 1.59955860e-04, 0.00000000e+00, ...,\n",
       "        0.00000000e+00, 0.00000000e+00, 1.54362162e-04],\n",
       "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "        2.42080670e-04, 0.00000000e+00, 0.00000000e+00],\n",
       "       [1.36017421e-04, 3.56222852e-04, 0.00000000e+00, ...,\n",
       "        5.06518874e-04, 2.86498871e-05, 1.66336235e-04]], dtype=float32)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adata.X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ce26650d-f8a3-4ef8-a62f-0c11fb9fd8df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>true_labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>73 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   true_labels\n",
       "0            1\n",
       "1            3\n",
       "2            1\n",
       "3            3\n",
       "4            3\n",
       "..         ...\n",
       "68           3\n",
       "69           0\n",
       "70           4\n",
       "71           4\n",
       "72           3\n",
       "\n",
       "[73 rows x 1 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adata.obs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ef03d9de-6476-45bc-9f52-361d344d1bc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class MyDataset(Dataset):\n",
    "    def __init__(self, X_train, y_train):\n",
    "        self.X_train = X_train\n",
    "        self.y_train = y_train\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X_train)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        X = self.X_train.iloc[idx].values  # Extract values from X_train DataFrame row\n",
    "        y = self.y_train.iloc[idx]  # Extract label from y_train DataFrame\n",
    "        return torch.tensor(X, dtype=torch.float), torch.tensor(y, dtype=torch.long)  # Convert to PyTorch tensors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9bf1a97-427a-46a0-a6e1-a36db6b26f15",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ba60cd56-398a-4090-8f2e-1ec7e42bbc3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def preprocess(adata):\n",
    "    \n",
    "    #adata.var_names_make_unique()\n",
    "        \n",
    "    \n",
    "    sc.pp.filter_genes(adata, min_cells=1)\n",
    "    \n",
    "    #sc.pp.log1p(adata)\n",
    "\n",
    "\n",
    "    #sc.pp.pca(adata)\n",
    "\n",
    "    sc.pp.normalize_total(adata)\n",
    "\n",
    "    sc.pp.neighbors(adata, use_rep='X')\n",
    "\n",
    "    '''\n",
    "    sc.tl.umap(adata)\n",
    "\n",
    "    lei = sc.tl.leiden(adata, key_added=\"leiden\")\n",
    "\n",
    "    sc.pl.umap(\n",
    "        adata,\n",
    "        color=[\"leiden\"],\n",
    "        legend_loc=\"on data\",\n",
    "    )\n",
    "    '''\n",
    "    \n",
    "    \n",
    "    return adata\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "afbe7b03-0969-43de-990a-a1f848a8c0c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.str_'>\n",
      "105\n",
      "105\n"
     ]
    }
   ],
   "source": [
    "print(type(labels[0]))\n",
    "labels_int = [eval(i) for i in labels]\n",
    "print(len(labels_int))\n",
    "labels_y = labels_int[:757]\n",
    "print(len(labels_y))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee091a6b-733d-430a-8738-0e9017bc7382",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0f8a7607-65e4-4d1b-b0b8-8f5d072447d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.datasets import MNIST\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# Define an Autoencoder (AE) model \n",
    "class AE(nn.Module):\n",
    "    def __init__(self, input_dim, latent_dim):\n",
    "        super(AE, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(input_dim, 1024),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(1024, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, latent_dim)\n",
    "        )\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(latent_dim, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 1024),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(1024, input_dim),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        latent_representation = self.encoder(x)\n",
    "        recon_batch = self.decoder(latent_representation)\n",
    "        return recon_batch, latent_representation\n",
    "\n",
    "    \n",
    "# Define a Multi-Layer Perceptron (MLP) model \n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim, dropout_prob=0.5):\n",
    "        super(MLP, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, 512)\n",
    "        self.fc2 = nn.Linear(512, 256)\n",
    "        self.dropout = nn.Dropout(dropout_prob)  # Dropout layer\n",
    "        self.fc3 = nn.Linear(256, output_dim)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        x = self.dropout(x)  # Apply dropout\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "207d2ea2-7be4-47d5-9245-ea8544283f78",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "46de1c1d-e5c8-4f71-8c21-3fd2b8d3787a",
   "metadata": {},
   "outputs": [],
   "source": [
    "gene_rankings = pd.read_csv(\"rnaSetRanks.csv\", sep=',', header=None).to_numpy()\n",
    "#ordered = order_list(gene_rankings, pd_celldata)\n",
    "\n",
    "def order_list(gene_rankings, pd_celldata):\n",
    "    ordered = [None] * len(pd_celldata.columns)\n",
    "    count = 0\n",
    "    for col in pd_celldata.columns:\n",
    "        ordered[count] = 0\n",
    "        for c in gene_rankings:\n",
    "            if(c[0] == col):\n",
    "                ordered[count]=c[1]\n",
    "        count += 1 \n",
    "    return ordered\n",
    "\n",
    "\n",
    "# Define your custom loss function with a list of gene rankings\n",
    "    \n",
    "    \n",
    "class CustomLoss(nn.Module):\n",
    "    def __init__(self, gene_rankings):\n",
    "        super(CustomLoss, self).__init__()\n",
    "        self.gene_rankings = nn.Parameter(torch.Tensor(gene_rankings), requires_grad=True)\n",
    "\n",
    "    def forward(self, y_true, y_pred):\n",
    "        # Calculate the weighted loss based on gene rankings\n",
    "        weighted_loss = torch.sum((1+(1/self.gene_rankings)) * torch.square(y_true - y_pred))\n",
    "        return weighted_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d69c0408-7b31-4a7c-b2e8-916a0c390386",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ordered = order_list(gene_rankings, pd_celldata)\n",
    "#ordered = ordered[1:]\n",
    "#ordered = torch.Tensor(ordered)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4e98243a-5b39-43bc-84a1-b9d955d6dd30",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ordered.requires_grad_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f9a53e35-4111-47a2-b994-0492f4793f29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9733\n"
     ]
    }
   ],
   "source": [
    "#custom_loss = CustomLoss(ordered)\n",
    "print(len(adata.var))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d03e4e73-0c65-470e-8f5d-1456d042bccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "latent_dim = 64\n",
    "input_dim = len(adata.var)\n",
    "output_dim = 10\n",
    "batch_size = 757\n",
    "\n",
    "num_epochs = 20\n",
    "\n",
    "hidden_dim = 256\n",
    "learning_rate = 0.001\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c2d135a9-3a69-4bb2-82df-aeae726ff622",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data_name = 'RNA_seq'\n",
    "\n",
    "# Initialize AE and MLP models with increased complexity and dropout\n",
    "ae = AE(input_dim, latent_dim)\n",
    "mlp = MLP(latent_dim, output_dim)\n",
    "\n",
    "# Combine AE and MLP models\n",
    "class CombinedModel(nn.Module):\n",
    "    def __init__(self, ae, mlp):\n",
    "        super(CombinedModel, self).__init__()\n",
    "        self.ae = ae\n",
    "        self.mlp = mlp\n",
    "    \n",
    "    def forward(self, x):\n",
    "        recon_batch, latent_representation = self.ae(x)\n",
    "        mlp_output = self.mlp(latent_representation)\n",
    "        return recon_batch, mlp_output\n",
    "\n",
    "# Create the combined model\n",
    "combined_model = CombinedModel(ae, mlp)\n",
    "\n",
    "autoencoder_criterion = nn.MSELoss()\n",
    "#autoencoder_criterion = nn.BCELoss()\n",
    "\n",
    "mlp_criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "\n",
    "optimizer_combined = optim.AdamW(combined_model.parameters(), lr=0.001)\n",
    "\n",
    "# Initialize the learning rate scheduler\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer_combined, step_size=5, gamma=0.5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f4307bbe-4a4a-4ae0-8669-804c9397a208",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get data loaders\n",
    "\n",
    "X_df_train = pd.DataFrame(X_train)\n",
    "y_df_train = pd.Series(y_train)\n",
    "\n",
    "dataset_train = MyDataset(X_df_train, y_df_train)\n",
    "train_loader = DataLoader(dataset_train, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "\n",
    "\n",
    "X_df_test = pd.DataFrame(X_test)\n",
    "y_df_test = pd.Series(y_test)\n",
    "\n",
    "dataset_test = MyDataset(X_df_test, y_df_test)\n",
    "test_loader = DataLoader(dataset_test, batch_size=batch_size, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0b8db9e8-79f9-475b-aaa5-ea08b3eb8359",
   "metadata": {},
   "outputs": [],
   "source": [
    "#labels_y=torch.FloatTensor(labels_y)\n",
    "#labels_y = labels_y.long()\n",
    "#custom_loss = CustomLoss(ordered)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "10468319-da59-4ba2-a702-2475e9c9a759",
   "metadata": {},
   "outputs": [],
   "source": [
    "def composite_loss(autoencoder_loss, mlp_loss, custom_loss_weight):\n",
    "    return autoencoder_loss + mlp_loss + (custom_loss_weight * custom_loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f01ed723-3ad8-4a2c-828f-a70b27ab68be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define your custom MSE loss function.\n",
    "class CustomMSELoss(nn.Module):\n",
    "    def __init__(self, gene_ranking, gene_importance_threshold, learning_rate):\n",
    "        super(CustomMSELoss, self).__init__()\n",
    "        self.gene_ranking = nn.Parameter(gene_ranking.clone().detach(), requires_grad=True)\n",
    "        self.gene_importance_threshold = gene_importance_threshold\n",
    "        self.learning_rate = learning_rate\n",
    "\n",
    "    def forward(self, predicted, target):\n",
    "        mse_loss = torch.mean((predicted - target)**2)\n",
    "\n",
    "        # Penalize less important genes\n",
    "        gene_penalty = torch.sum(torch.relu(self.gene_ranking - self.gene_importance_threshold))\n",
    "        total_loss = mse_loss + gene_penalty\n",
    "\n",
    "        return total_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "34e2f742-4e4b-4417-bd9c-6fb757a93744",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "105"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "66c25f04-4cd2-48e8-bc3b-de8ab732dcfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "<class 'pandas.core.series.Series'>\n"
     ]
    }
   ],
   "source": [
    "print(type(X_train))\n",
    "print(type(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "af884fcc-3617-47d4-bb56-ff8af0528e9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/50], Batch [0/1], AE Loss: 0.2169, MLP Loss: 2.3182\n",
      "Epoch [1/50], Combined Model Accuracy on Validation/Test dataset: 15.62%\n",
      "Epoch [2/50], Batch [0/1], AE Loss: 0.2090, MLP Loss: 2.1662\n",
      "Epoch [2/50], Combined Model Accuracy on Validation/Test dataset: 31.25%\n",
      "Epoch [3/50], Batch [0/1], AE Loss: 0.1651, MLP Loss: 1.7080\n",
      "Epoch [3/50], Combined Model Accuracy on Validation/Test dataset: 31.25%\n",
      "Epoch [4/50], Batch [0/1], AE Loss: 0.1325, MLP Loss: 1.4161\n",
      "Epoch [4/50], Combined Model Accuracy on Validation/Test dataset: 21.88%\n",
      "Epoch [5/50], Batch [0/1], AE Loss: 0.1391, MLP Loss: 1.9354\n",
      "Epoch [5/50], Combined Model Accuracy on Validation/Test dataset: 28.12%\n",
      "Epoch [6/50], Batch [0/1], AE Loss: 0.1387, MLP Loss: 2.3649\n",
      "Epoch [6/50], Combined Model Accuracy on Validation/Test dataset: 34.38%\n",
      "Epoch [7/50], Batch [0/1], AE Loss: 0.1353, MLP Loss: 1.5370\n",
      "Epoch [7/50], Combined Model Accuracy on Validation/Test dataset: 31.25%\n",
      "Epoch [8/50], Batch [0/1], AE Loss: 0.1319, MLP Loss: 1.2987\n",
      "Epoch [8/50], Combined Model Accuracy on Validation/Test dataset: 31.25%\n",
      "Epoch [9/50], Batch [0/1], AE Loss: 0.1287, MLP Loss: 1.2442\n",
      "Epoch [9/50], Combined Model Accuracy on Validation/Test dataset: 50.00%\n",
      "Epoch [10/50], Batch [0/1], AE Loss: 0.1252, MLP Loss: 1.2128\n",
      "Epoch [10/50], Combined Model Accuracy on Validation/Test dataset: 50.00%\n",
      "Epoch [11/50], Batch [0/1], AE Loss: 0.1217, MLP Loss: 1.1793\n",
      "Epoch [11/50], Combined Model Accuracy on Validation/Test dataset: 46.88%\n",
      "Epoch [12/50], Batch [0/1], AE Loss: 0.1202, MLP Loss: 1.1434\n",
      "Epoch [12/50], Combined Model Accuracy on Validation/Test dataset: 46.88%\n",
      "Epoch [13/50], Batch [0/1], AE Loss: 0.1190, MLP Loss: 1.0913\n",
      "Epoch [13/50], Combined Model Accuracy on Validation/Test dataset: 53.12%\n",
      "Epoch [14/50], Batch [0/1], AE Loss: 0.1180, MLP Loss: 1.0308\n",
      "Epoch [14/50], Combined Model Accuracy on Validation/Test dataset: 53.12%\n",
      "Epoch [15/50], Batch [0/1], AE Loss: 0.1172, MLP Loss: 0.9660\n",
      "Epoch [15/50], Combined Model Accuracy on Validation/Test dataset: 53.12%\n",
      "Epoch [16/50], Batch [0/1], AE Loss: 0.1165, MLP Loss: 0.9009\n",
      "Epoch [16/50], Combined Model Accuracy on Validation/Test dataset: 56.25%\n",
      "Epoch [17/50], Batch [0/1], AE Loss: 0.1161, MLP Loss: 0.8673\n",
      "Epoch [17/50], Combined Model Accuracy on Validation/Test dataset: 53.12%\n",
      "Epoch [18/50], Batch [0/1], AE Loss: 0.1157, MLP Loss: 0.8320\n",
      "Epoch [18/50], Combined Model Accuracy on Validation/Test dataset: 53.12%\n",
      "Epoch [19/50], Batch [0/1], AE Loss: 0.1153, MLP Loss: 0.7952\n",
      "Epoch [19/50], Combined Model Accuracy on Validation/Test dataset: 56.25%\n",
      "Epoch [20/50], Batch [0/1], AE Loss: 0.1150, MLP Loss: 0.7575\n",
      "Epoch [20/50], Combined Model Accuracy on Validation/Test dataset: 59.38%\n",
      "Epoch [21/50], Batch [0/1], AE Loss: 0.1148, MLP Loss: 0.7190\n",
      "Epoch [21/50], Combined Model Accuracy on Validation/Test dataset: 56.25%\n",
      "Epoch [22/50], Batch [0/1], AE Loss: 0.1147, MLP Loss: 0.6990\n",
      "Epoch [22/50], Combined Model Accuracy on Validation/Test dataset: 56.25%\n",
      "Epoch [23/50], Batch [0/1], AE Loss: 0.1146, MLP Loss: 0.6781\n",
      "Epoch [23/50], Combined Model Accuracy on Validation/Test dataset: 56.25%\n",
      "Epoch [24/50], Batch [0/1], AE Loss: 0.1145, MLP Loss: 0.6566\n",
      "Epoch [24/50], Combined Model Accuracy on Validation/Test dataset: 62.50%\n",
      "Epoch [25/50], Batch [0/1], AE Loss: 0.1144, MLP Loss: 0.6347\n",
      "Epoch [25/50], Combined Model Accuracy on Validation/Test dataset: 62.50%\n",
      "Epoch [26/50], Batch [0/1], AE Loss: 0.1143, MLP Loss: 0.6128\n",
      "Epoch [26/50], Combined Model Accuracy on Validation/Test dataset: 62.50%\n",
      "Epoch [27/50], Batch [0/1], AE Loss: 0.1142, MLP Loss: 0.6018\n",
      "Epoch [27/50], Combined Model Accuracy on Validation/Test dataset: 62.50%\n",
      "Epoch [28/50], Batch [0/1], AE Loss: 0.1141, MLP Loss: 0.5908\n",
      "Epoch [28/50], Combined Model Accuracy on Validation/Test dataset: 62.50%\n",
      "Epoch [29/50], Batch [0/1], AE Loss: 0.1141, MLP Loss: 0.5798\n",
      "Epoch [29/50], Combined Model Accuracy on Validation/Test dataset: 65.62%\n",
      "Epoch [30/50], Batch [0/1], AE Loss: 0.1140, MLP Loss: 0.5689\n",
      "Epoch [30/50], Combined Model Accuracy on Validation/Test dataset: 68.75%\n",
      "Epoch [31/50], Batch [0/1], AE Loss: 0.1138, MLP Loss: 0.5582\n",
      "Epoch [31/50], Combined Model Accuracy on Validation/Test dataset: 68.75%\n",
      "Epoch [32/50], Batch [0/1], AE Loss: 0.1138, MLP Loss: 0.5529\n",
      "Epoch [32/50], Combined Model Accuracy on Validation/Test dataset: 68.75%\n",
      "Epoch [33/50], Batch [0/1], AE Loss: 0.1137, MLP Loss: 0.5476\n",
      "Epoch [33/50], Combined Model Accuracy on Validation/Test dataset: 68.75%\n",
      "Epoch [34/50], Batch [0/1], AE Loss: 0.1137, MLP Loss: 0.5424\n",
      "Epoch [34/50], Combined Model Accuracy on Validation/Test dataset: 68.75%\n",
      "Epoch [35/50], Batch [0/1], AE Loss: 0.1136, MLP Loss: 0.5371\n",
      "Epoch [35/50], Combined Model Accuracy on Validation/Test dataset: 68.75%\n",
      "Epoch [36/50], Batch [0/1], AE Loss: 0.1135, MLP Loss: 0.5319\n",
      "Epoch [36/50], Combined Model Accuracy on Validation/Test dataset: 68.75%\n",
      "Epoch [37/50], Batch [0/1], AE Loss: 0.1135, MLP Loss: 0.5293\n",
      "Epoch [37/50], Combined Model Accuracy on Validation/Test dataset: 71.88%\n",
      "Epoch [38/50], Batch [0/1], AE Loss: 0.1134, MLP Loss: 0.5267\n",
      "Epoch [38/50], Combined Model Accuracy on Validation/Test dataset: 71.88%\n",
      "Epoch [39/50], Batch [0/1], AE Loss: 0.1134, MLP Loss: 0.5241\n",
      "Epoch [39/50], Combined Model Accuracy on Validation/Test dataset: 71.88%\n",
      "Epoch [40/50], Batch [0/1], AE Loss: 0.1134, MLP Loss: 0.5215\n",
      "Epoch [40/50], Combined Model Accuracy on Validation/Test dataset: 71.88%\n",
      "Epoch [41/50], Batch [0/1], AE Loss: 0.1133, MLP Loss: 0.5190\n",
      "Epoch [41/50], Combined Model Accuracy on Validation/Test dataset: 71.88%\n",
      "Epoch [42/50], Batch [0/1], AE Loss: 0.1133, MLP Loss: 0.5177\n",
      "Epoch [42/50], Combined Model Accuracy on Validation/Test dataset: 71.88%\n",
      "Epoch [43/50], Batch [0/1], AE Loss: 0.1133, MLP Loss: 0.5164\n",
      "Epoch [43/50], Combined Model Accuracy on Validation/Test dataset: 71.88%\n",
      "Epoch [44/50], Batch [0/1], AE Loss: 0.1133, MLP Loss: 0.5151\n",
      "Epoch [44/50], Combined Model Accuracy on Validation/Test dataset: 71.88%\n",
      "Epoch [45/50], Batch [0/1], AE Loss: 0.1132, MLP Loss: 0.5138\n",
      "Epoch [45/50], Combined Model Accuracy on Validation/Test dataset: 71.88%\n",
      "Epoch [46/50], Batch [0/1], AE Loss: 0.1132, MLP Loss: 0.5125\n",
      "Epoch [46/50], Combined Model Accuracy on Validation/Test dataset: 71.88%\n",
      "Epoch [47/50], Batch [0/1], AE Loss: 0.1132, MLP Loss: 0.5118\n",
      "Epoch [47/50], Combined Model Accuracy on Validation/Test dataset: 71.88%\n",
      "Epoch [48/50], Batch [0/1], AE Loss: 0.1132, MLP Loss: 0.5112\n",
      "Epoch [48/50], Combined Model Accuracy on Validation/Test dataset: 71.88%\n",
      "Epoch [49/50], Batch [0/1], AE Loss: 0.1132, MLP Loss: 0.5105\n",
      "Epoch [49/50], Combined Model Accuracy on Validation/Test dataset: 71.88%\n",
      "Epoch [50/50], Batch [0/1], AE Loss: 0.1132, MLP Loss: 0.5099\n",
      "Epoch [50/50], Combined Model Accuracy on Validation/Test dataset: 71.88%\n"
     ]
    }
   ],
   "source": [
    "gene_importance_threshold = 0.1\n",
    "#custom_loss = CustomMSELoss(ordered, gene_importance_threshold, learning_rate)\n",
    "\n",
    "num_epochs = 50\n",
    "# Training loop\n",
    "for epoch in range(num_epochs):\n",
    "    for batch_idx, (X_train, y_train) in enumerate(train_loader):\n",
    "        X_train = X_train.view(X_train.size(0), -1)\n",
    "\n",
    "        optimizer_combined.zero_grad()\n",
    "        recon_batch, mlp_output_train = combined_model(X_train)\n",
    "\n",
    "\n",
    "        # Calculate AE loss (reconstruction loss)\n",
    "        #ae_loss = custom_loss(recon_batch, data)\n",
    "        ae_loss = nn.MSELoss()(recon_batch, X_train)\n",
    "        \n",
    "\n",
    "        # Calculate MLP loss \n",
    "        mlp_loss = nn.CrossEntropyLoss()(mlp_output_train, y_train)\n",
    "      \n",
    "        # Total loss\n",
    "        total_loss = ae_loss + mlp_loss\n",
    "\n",
    "        optimizer_combined.zero_grad()\n",
    "        total_loss.backward(retain_graph=True)\n",
    "        \n",
    "        \n",
    "        optimizer_combined.step()\n",
    "\n",
    "        #ordered.grad = torch.autograd.grad(ae_loss, custom_loss.gene_ranking)[0]\n",
    "        \n",
    "        if batch_idx % 100 == 0:\n",
    "            print(f'Epoch [{epoch+1}/{num_epochs}], Batch [{batch_idx}/{len(train_loader)}], AE Loss: {ae_loss.item():.4f}, MLP Loss: {mlp_loss.item():.4f}')\n",
    "\n",
    "    # Step the learning rate scheduler\n",
    "    scheduler.step()\n",
    "\n",
    "    # Evaluate accuracy on validation/test dataset\n",
    "    combined_model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for X_test, y_test in test_loader:  \n",
    "            X_test = X_test.view(X_test.size(0), -1)\n",
    "            _, mlp_output = combined_model(X_test)\n",
    "            _, predicted = torch.max(mlp_output, 1)\n",
    "            total += y_test.size(0)\n",
    "            correct += (predicted == y_test).sum().item()\n",
    "\n",
    "\n",
    "            \n",
    "    accuracy = correct / total\n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Combined Model Accuracy on Validation/Test dataset: {100 * accuracy:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "913849ca-07fa-4073-ae99-03941543fa43",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2d00a2e7-0a96-4a08-8fc9-1e47da717827",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ordered' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_3971224/591319919.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m             \u001b[0;31m# Use the custom loss function with the current gene rankings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m             \u001b[0moptimizer_combined\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m             \u001b[0mgene_rankings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mordered\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequires_grad_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m             \u001b[0mrecon_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmlp_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcombined_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecon_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'ordered' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "# Convergence criteria\n",
    "max_iterations = 10  # Adjust as needed\n",
    "convergence_threshold = 0.001  # Adjust as needed\n",
    "\n",
    "for iteration in range(max_iterations):\n",
    "    # Train the model with the current gene rankings\n",
    "    for epoch in range(num_epochs):\n",
    "        for batch_idx, (data, labels) in enumerate(train_loader):\n",
    "            data = data.view(data.size(0), -1)\n",
    "            # Forward pass, compute loss, and backpropagate\n",
    "            # Use the custom loss function with the current gene rankings\n",
    "            optimizer_combined.zero_grad()\n",
    "            gene_rankings = ordered.clone().detach().requires_grad_(True)\n",
    "            recon_batch, mlp_output = combined_model(data)\n",
    "            print(recon_batch)\n",
    "            print(mlp_output)\n",
    "            print(labels)\n",
    "            loss = CustomLoss(ordered)(latent_representation, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        # Check for convergence by comparing updated gene rankings\n",
    "        new_gene_rankings = ordered.detach().numpy()\n",
    "        if torch.norm(new_gene_rankings - ordered) < convergence_threshold:\n",
    "            break  # Converged\n",
    "\n",
    "        # Update gene rankings based on the current model (you can define your update logic)\n",
    "        ordered = new_gene_rankings\n",
    "\n",
    "# Final gene rankings after convergence\n",
    "final_gene_rankings = new_gene_rankings\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4101957-8a61-46c3-ab28-109aab99edb1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5567921-9a13-47f2-bc59-5fe76bd748d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ae_loss)\n",
    "print(mlp_loss)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
